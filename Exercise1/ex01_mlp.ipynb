{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d487ed2",
   "metadata": {},
   "source": [
    "### This file consists of the same preprocessing pipeline as ex01_V2, hence we will not comment on any of the preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99065601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import zero_one_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83762849",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_train_dev = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vTOZ2rC82rhNsJduoyKYTsVeH6ukd7Bpxvxn_afOibn3R-eadZGXu82eCU9IRpl4CK_gefEGsYrA_oM/pub?gid=1863430984&single=true&output=tsv'\n",
    "url_test = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vT-KNR9nuYatLkSbzSRgpz6Ku1n4TN4w6kKmFLkA6QJHTfQzmX0puBsLF7PAAQJQAxUpgruDd_RRgK7/pub?gid=417546901&single=true&output=tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08497d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "import requests\n",
    "\n",
    "def load_dataset(url):\n",
    "    r = requests.get(url)\n",
    "    data = r.content.decode('utf8')\n",
    "    df = pd.read_csv(StringIO(data), sep='\\t')\n",
    "    df.columns = ['tweet', 'label']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aec8f40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_dev = load_dataset(url_train_dev)\n",
    "df_test = load_dataset(url_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "628d85f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_lowercase(txt):\n",
    "    txt = txt.lower()\n",
    "    return txt\n",
    "\n",
    "def remove_url(text):\n",
    "    re_url = re.compile('https?://\\S+|www\\.\\S+')\n",
    "    return re_url.sub('', text)  # I received an TypeError, so i changed 'text' to str(text) \n",
    "\n",
    "import string\n",
    "exclude = string.punctuation\n",
    "def remove_punc(text):\n",
    "    return text.translate(str.maketrans('', '', exclude))\n",
    "\n",
    "import emoji\n",
    "def demojize_emojis(text):\n",
    "    return emoji.demojize(text)\n",
    "\n",
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)\n",
    "    \n",
    "# function to remove special characters\n",
    "def remove_special(text):\n",
    "    x=''\n",
    "    for i in text:\n",
    "        if i.isalnum():\n",
    "            x=x+i\n",
    "        else:\n",
    "            x=x+' '\n",
    "    return x\n",
    "\n",
    "# not sure if this is needed;\n",
    "def none_to_empty_string(text):\n",
    "    if not text:\n",
    "        text = \"\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37494548",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dev = df_train_dev['tweet'].apply(remove_emoji)\n",
    "X_train_dev = X_train_dev.apply(convert_lowercase)\n",
    "X_train_dev = X_train_dev.apply(remove_url)\n",
    "X_train_dev = X_train_dev.apply(remove_punc)\n",
    "X_train_dev = X_train_dev.apply(none_to_empty_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3520dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_encoder(v, d):\n",
    "    if d == None:\n",
    "        d = {}\n",
    "    cur_value = 0\n",
    "    for i in range(len(v)):\n",
    "        if v[i] in d:\n",
    "            v[i] = d[v[i]]\n",
    "        else:\n",
    "            d[v[i]] = cur_value\n",
    "            v[i] = d[v[i]]\n",
    "            cur_value += 1\n",
    "    return v, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bd3b62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_dev, current_dictionary = custom_encoder(df_train_dev['label'], None)\n",
    "y_train_dev = y_train_dev.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4118fbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_dev, y_train_dev, test_size=0.1, random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3adc592e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(stop_words=None)\n",
    "vectorizer.fit(X_train)\n",
    "X_train = vectorizer.transform(X_train)\n",
    "X_val = vectorizer.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e888a780",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test['tweet'].apply(remove_emoji)\n",
    "X_test = X_test.apply(convert_lowercase)\n",
    "X_test = X_test.apply(remove_url)\n",
    "X_test = X_test.apply(remove_punc)\n",
    "X_test = X_test.apply(none_to_empty_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61941dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vectorizer.transform(X_test)\n",
    "y_test = custom_encoder(df_test['label'], current_dictionary)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4020854e",
   "metadata": {},
   "source": [
    "### Now, we will use the MLP as our model instead of a linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786813e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = MLPClassifier(random_state=99, max_iter=100)\n",
    "mod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635d4316",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = mod.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b068d7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((1 - zero_one_loss(y_val, y_pred))*100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c81dc2",
   "metadata": {},
   "source": [
    "let's look at the performance on test data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
